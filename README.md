3D-semantic-map on mobile robot (tx1,ros1)

a system implemented on amobilerobot capable of performing semantic segmenta-tion and 3D mapping of indoor environments, as well as enabling voice interaction. The mobile robot interprets the indoor environment through a camera, achieving semantic segmentation of the scene. Once mapping is completed, it can navigate to semantic targets. Additionally, the robot accepts voice commands and responds accordingly, enabling navigation to target points via voice instructions. The robot utilizes YOLOv3 for object detection, and upon detection, crops the point cloud and aggregates it to obtain the coordinates of objects in the global coordinate system. The Hungarian algorithm combined with a Kalman filter is employed for object tracking. After completing semantic segmentation of the indoor environment, the system integrates prior models with laser SLAM maps to achieve 3D semantic model reconstruction of the indoor environment. Subsequently, a path planner is used to enable the ro-bot to navigate to target objects. Command word recognition is employed to process voice commands, guiding the robot to navigate to the designated target point.

Demostration is as followes:
![demo.gif](https://github.com/Gugu-c/3D-semantic-map/blob/main/demo.gif)
